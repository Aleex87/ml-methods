{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03de5e51",
   "metadata": {},
   "source": [
    "# Supervised Learning → Random Forest (Classification)\n",
    "\n",
    "This notebook is part of the **ML-Methods** project.\n",
    "\n",
    "As with the other classification notebooks,\n",
    "the first sections focus on data preparation\n",
    "and are intentionally repeated.\n",
    "\n",
    "This ensures consistency across models\n",
    "and allows fair comparison of results.\n",
    "\n",
    "1. Project setup and common pipeline\n",
    "2. Dataset loading\n",
    "3. Train-test split\n",
    "4. Feature scaling (why we do it)\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "5. What is this model? (Intuition)\n",
    "6. Model training\n",
    "7. Model behavior and key parameters\n",
    "8. Predictions\n",
    "9. Model evaluation\n",
    "10. When to use it and when not to\n",
    "11. Model persistence\n",
    "12. Mathematical formulation (deep dive)\n",
    "13. Final summary – Code only\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## How this notebook should be read\n",
    "\n",
    "This notebook is designed to be read **top to bottom**.\n",
    "\n",
    "Before every code cell, you will find a short explanation describing:\n",
    "- what we are about to do\n",
    "- why this step is necessary\n",
    "- how it fits into the overall process\n",
    "\n",
    "The goal is not just to run the code,\n",
    "but to understand what is happening at each step\n",
    "and be able to adapt it to your own data.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What is Random Forest Classification?\n",
    "\n",
    "Random Forest Classification is an **ensemble classification model**\n",
    "that combines the predictions of many decision trees.\n",
    "\n",
    "Instead of relying on a single classifier,\n",
    "Random Forest aggregates the decisions\n",
    "of multiple independent models\n",
    "to produce a final prediction.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## Why we start with intuition\n",
    "\n",
    "Random Forest may look complex,\n",
    "but its core idea is simple.\n",
    "\n",
    "Each decision tree makes a prediction.\n",
    "Some trees make mistakes,\n",
    "but many trees together tend to agree\n",
    "on the correct class.\n",
    "\n",
    "Understanding this idea of\n",
    "**many weak classifiers working together**\n",
    "is key to understanding Random Forest.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What you should expect from the results\n",
    "\n",
    "With Random Forest Classification, you should expect:\n",
    "- strong performance on non-linear problems\n",
    "- robustness to noise and outliers\n",
    "- stable predictions without heavy tuning\n",
    "\n",
    "However:\n",
    "- interpretability is lower than linear models\n",
    "- training and memory usage are higher\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf7d97",
   "metadata": {},
   "source": [
    "_________________________________________________\n",
    "\n",
    "## 1. Project setup and common pipeline\n",
    "\n",
    "In this section we set up the common pipeline\n",
    "used across classification models in this project.\n",
    "\n",
    "Although Random Forest does not require feature scaling,\n",
    "we keep scaling for pipeline consistency\n",
    "and fair model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1421479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports used across all classification models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a660f34",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 2. Dataset loading\n",
    "\n",
    "In this section we load the dataset\n",
    "used for the Random Forest classification task.\n",
    "\n",
    "We use the same dataset as in the other classification models\n",
    "to allow a fair and direct comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc3c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff007dfb",
   "metadata": {},
   "source": [
    "### Inputs and target\n",
    "\n",
    "- `X` contains the input features\n",
    "- `y` contains the target labels\n",
    "\n",
    "This is a binary classification problem,\n",
    "where each sample belongs to one of two classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb5805",
   "metadata": {},
   "source": [
    "### Why using the same dataset matters\n",
    "\n",
    "Using the same dataset across classification models\n",
    "allows us to:\n",
    "- isolate the effect of the model choice\n",
    "- compare performance objectively\n",
    "- better understand model-specific behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a0a60f",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 3. Train-test split\n",
    "\n",
    "In this section we split the dataset\n",
    "into training and test sets.\n",
    "\n",
    "This step allows us to evaluate\n",
    "how well the Random Forest classifier generalizes\n",
    "to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0aa8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826cc95",
   "metadata": {},
   "source": [
    "### Why this step is important\n",
    "\n",
    "A classification model must be evaluated\n",
    "on data it has never seen during training.\n",
    "\n",
    "By separating the data:\n",
    "- the training set is used to build the model\n",
    "- the test set is used only for evaluation\n",
    "\n",
    "This prevents overly optimistic results\n",
    "and reflects real-world performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40307aa",
   "metadata": {},
   "source": [
    "### Note on split proportions\n",
    "\n",
    "The choice of train-test split\n",
    "depends on the dataset and the problem context.\n",
    "\n",
    "Common splits include:\n",
    "- 80 / 20\n",
    "- 70 / 30\n",
    "- 90 / 10\n",
    "\n",
    "In this notebook, we use an 80 / 20 split\n",
    "as a reasonable default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ae01a",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 4. Feature scaling (why we do it)\n",
    "\n",
    "In this section we apply feature scaling\n",
    "to the input features.\n",
    "\n",
    "Random Forest does **not require** feature scaling\n",
    "to function correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8dc85",
   "metadata": {},
   "source": [
    "### Why scaling is not required for Random Forest\n",
    "\n",
    "Random Forest is based on decision trees.\n",
    "\n",
    "Decision trees:\n",
    "- split data using feature thresholds\n",
    "- are invariant to feature scale\n",
    "- depend on feature order, not magnitude\n",
    "\n",
    "For this reason, scaling does not change\n",
    "how Random Forest builds its trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78144f",
   "metadata": {},
   "source": [
    "### Why we still apply scaling\n",
    "\n",
    "Even though scaling is not required,\n",
    "we keep it in the pipeline to:\n",
    "\n",
    "- maintain consistency across classification models\n",
    "- allow fair model comparison\n",
    "- reuse the same preprocessing steps\n",
    "- avoid conditional logic in the code\n",
    "\n",
    "This makes the overall project\n",
    "simpler and more maintainable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d20dd",
   "metadata": {},
   "source": [
    "### Important rule: fit only on training data\n",
    "\n",
    "As with all preprocessing steps:\n",
    "- the scaler is fitted only on the training data\n",
    "- the same scaler is applied to test data\n",
    "\n",
    "This prevents data leakage\n",
    "and ensures fair evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426bd09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (kept for pipeline consistency)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449634af",
   "metadata": {},
   "source": [
    "### What we have after this step\n",
    "\n",
    "- scaled training data\n",
    "- scaled test data\n",
    "- a consistent preprocessing pipeline\n",
    "\n",
    "At this point, the data is ready\n",
    "to be used by the Random Forest classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2fa48",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 5. What is this model? (Random Forest Classification)\n",
    "\n",
    "Before training the model, it is important to understand\n",
    "what Random Forest Classification does conceptually.\n",
    "\n",
    "Random Forest Classification is an **ensemble classifier**\n",
    "that combines the decisions of many decision trees\n",
    "to assign a final class label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9ceb78",
   "metadata": {},
   "source": [
    "### The core idea\n",
    "\n",
    "Instead of relying on a single decision tree,\n",
    "Random Forest builds **many trees**.\n",
    "\n",
    "Each tree:\n",
    "- sees a slightly different version of the data\n",
    "- makes its own classification decision\n",
    "\n",
    "The final prediction is obtained by:\n",
    "- collecting the predictions of all trees\n",
    "- selecting the class with the majority of votes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cbe5e",
   "metadata": {},
   "source": [
    "### Why many trees work better than one\n",
    "\n",
    "Individual decision trees:\n",
    "- are easy to understand\n",
    "- but tend to overfit the training data\n",
    "\n",
    "Random Forest reduces overfitting by:\n",
    "- training trees on different subsets of data\n",
    "- introducing randomness in feature selection\n",
    "- aggregating many independent decisions\n",
    "\n",
    "Errors made by individual trees\n",
    "tend to cancel out when combined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d39ffd",
   "metadata": {},
   "source": [
    "### How this differs from other classifiers\n",
    "\n",
    "Compared to Logistic Regression:\n",
    "- Random Forest captures non-linear relationships\n",
    "- it does not assume a linear decision boundary\n",
    "\n",
    "Compared to KNN:\n",
    "- Random Forest learns a model during training\n",
    "- prediction does not require storing all training samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39946e60",
   "metadata": {},
   "source": [
    "### Strengths and weaknesses\n",
    "\n",
    "Strengths:\n",
    "- strong performance on complex data\n",
    "- robustness to noise and outliers\n",
    "- minimal preprocessing requirements\n",
    "\n",
    "Weaknesses:\n",
    "- reduced interpretability\n",
    "- higher computational cost\n",
    "- larger memory footprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f8be24",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Random Forest Classification answers the question:\n",
    "\"What do many different decision trees predict?\"\n",
    "\n",
    "By combining these predictions,\n",
    "it produces robust and accurate classifications\n",
    "on a wide range of problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78088739",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 6. Model training (Random Forest Classification)\n",
    "\n",
    "In this section we train the Random Forest classifier\n",
    "using the prepared training data.\n",
    "\n",
    "Unlike KNN, Random Forest performs real training:\n",
    "it builds multiple decision trees\n",
    "and learns patterns from the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73735971",
   "metadata": {},
   "source": [
    "### What does \"training\" mean for Random Forest?\n",
    "\n",
    "Training a Random Forest classifier means:\n",
    "\n",
    "- building many decision trees\n",
    "- each tree is trained on a random subset of the training data\n",
    "- each split considers only a random subset of features\n",
    "\n",
    "This controlled randomness helps:\n",
    "- reduce overfitting\n",
    "- improve generalization\n",
    "- increase robustness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87c5f2",
   "metadata": {},
   "source": [
    "### Important hyperparameters (introduced, not tuned)\n",
    "\n",
    "At this stage, we focus on understanding the model,\n",
    "not on optimizing its performance.\n",
    "\n",
    "We start with a simple and commonly used configuration.\n",
    "Hyperparameter tuning can be explored later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6739058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>Note: This parameter is tree-specific.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>The \"balanced_subsample\" mode is the same as \"balanced\" except that<br>weights are computed based on the bootstrap sample for every tree<br>grown.<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756424ff",
   "metadata": {},
   "source": [
    "### What these parameters mean\n",
    "\n",
    "- `n_estimators=100`  \n",
    "  Number of decision trees in the forest.  \n",
    "  More trees usually improve stability, but increase computation.\n",
    "\n",
    "- `random_state=42`  \n",
    "  Ensures reproducibility of results.\n",
    "\n",
    "- `n_jobs=-1`  \n",
    "  Uses all available CPU cores to speed up training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77d5ee2",
   "metadata": {},
   "source": [
    "### What we have after training\n",
    "\n",
    "After this step:\n",
    "- multiple decision trees have been trained\n",
    "- each tree has learned different decision rules\n",
    "- the forest is ready to make predictions\n",
    "\n",
    "Training is computationally heavier than KNN,\n",
    "but prediction is faster on large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781717aa",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 7. Model behavior and key parameters (Random Forest Classification)\n",
    "\n",
    "In this section we analyze how Random Forest Classification behaves\n",
    "and which parameters most strongly influence its predictions.\n",
    "\n",
    "Random Forest does not produce simple, interpretable coefficients,\n",
    "but its behavior can still be understood at a high level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56502759",
   "metadata": {},
   "source": [
    "### Number of trees (`n_estimators`)\n",
    "\n",
    "The number of trees controls:\n",
    "- model stability\n",
    "- variance reduction\n",
    "\n",
    "General behavior:\n",
    "- few trees → higher variance\n",
    "- many trees → more stable predictions\n",
    "\n",
    "Beyond a certain point,\n",
    "adding more trees provides diminishing returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c240a27",
   "metadata": {},
   "source": [
    "### Tree depth and complexity\n",
    "\n",
    "Each decision tree can grow deep and complex.\n",
    "\n",
    "Key parameters that control tree complexity include:\n",
    "- maximum tree depth\n",
    "- minimum samples per split\n",
    "- minimum samples per leaf\n",
    "\n",
    "Deeper trees:\n",
    "- capture fine details\n",
    "- risk overfitting\n",
    "\n",
    "Shallower trees:\n",
    "- generalize better\n",
    "- may underfit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c219b12",
   "metadata": {},
   "source": [
    "### Feature randomness\n",
    "\n",
    "At each split, Random Forest considers\n",
    "only a random subset of features.\n",
    "\n",
    "This randomness:\n",
    "- decorrelates trees\n",
    "- reduces overfitting\n",
    "- improves ensemble performance\n",
    "\n",
    "It is one of the main reasons\n",
    "Random Forest performs well in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98926ce7",
   "metadata": {},
   "source": [
    "### Voting mechanism\n",
    "\n",
    "For classification:\n",
    "- each tree outputs a class prediction\n",
    "- the final class is chosen by majority vote\n",
    "\n",
    "This voting process:\n",
    "- smooths individual tree errors\n",
    "- improves prediction robustness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d879bf",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Random Forest Classification behavior is driven by:\n",
    "- how many trees are used\n",
    "- how complex each tree is\n",
    "- how much randomness is introduced\n",
    "\n",
    "Understanding these elements helps explain\n",
    "why Random Forest often performs strongly\n",
    "without heavy tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cabc59e",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 8. Predictions (Random Forest Classification)\n",
    "\n",
    "In this section we use the trained Random Forest classifier\n",
    "to generate predictions on unseen test data.\n",
    "\n",
    "As with other classification models,\n",
    "it is important to distinguish between:\n",
    "- predicted class labels\n",
    "- predicted class probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb96a1",
   "metadata": {},
   "source": [
    "### Predicting class labels\n",
    "\n",
    "The `predict` method returns the final class prediction\n",
    "for each sample in the test set.\n",
    "\n",
    "For Random Forest:\n",
    "- each decision tree predicts a class\n",
    "- the final class is chosen by majority voting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6171ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict class labels on the test set\n",
    "\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c925ab",
   "metadata": {},
   "source": [
    "### Predicting class probabilities\n",
    "\n",
    "The `predict_proba` method returns class probabilities.\n",
    "\n",
    "For Random Forest:\n",
    "- each tree votes for a class\n",
    "- probabilities represent the fraction of trees\n",
    "  predicting each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732a919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(class 0)</th>\n",
       "      <th>P(class 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P(class 0)  P(class 1)\n",
       "0        0.03        0.97\n",
       "1        1.00        0.00\n",
       "2        1.00        0.00\n",
       "3        0.01        0.99\n",
       "4        0.00        1.00\n",
       "5        1.00        0.00\n",
       "6        1.00        0.00\n",
       "7        0.84        0.16\n",
       "8        0.65        0.35\n",
       "9        0.06        0.94"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict class probabilities on the test set\n",
    "\n",
    "y_pred_proba = rf_model.predict_proba(X_test_scaled)\n",
    "\n",
    "pd.DataFrame(\n",
    "    y_pred_proba[:10],\n",
    "    columns=[\"P(class 0)\", \"P(class 1)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1045a",
   "metadata": {},
   "source": [
    "### Interpreting Random Forest probabilities\n",
    "\n",
    "Random Forest probabilities:\n",
    "- reflect consensus among trees\n",
    "- are generally more stable than KNN probabilities\n",
    "- are less directly interpretable than Logistic Regression\n",
    "\n",
    "High probability means:\n",
    "- many trees agree on the prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b3ad7",
   "metadata": {},
   "source": [
    "### What you should expect to observe\n",
    "\n",
    "With Random Forest Classification, you should expect:\n",
    "- confident predictions for clear cases\n",
    "- smoother probability estimates than KNN\n",
    "- strong performance on complex, non-linear data\n",
    "\n",
    "These predictions will be evaluated\n",
    "in the next section using classification metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e8ee5",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 9. Model evaluation (Random Forest Classification)\n",
    "\n",
    "In this section we evaluate the performance of the Random Forest classifier\n",
    "on unseen test data.\n",
    "\n",
    "For classification models, evaluation requires\n",
    "analyzing both overall performance\n",
    "and the types of errors the model makes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f885e0cf",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Accuracy measures the proportion of correctly classified samples.\n",
    "\n",
    "It provides a high-level overview of model performance,\n",
    "but it does not capture the full error structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2f0583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3485b7",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "The confusion matrix compares predicted labels\n",
    "with true labels.\n",
    "\n",
    "It allows us to identify:\n",
    "- correct classifications\n",
    "- false positives\n",
    "- false negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1594619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  3],\n",
       "       [ 1, 70]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0708d",
   "metadata": {},
   "source": [
    "### Confusion matrix visualization\n",
    "\n",
    "A visual representation of the confusion matrix\n",
    "makes patterns of errors easier to interpret.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c98b53df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize confusion matrix\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=rf_model.classes_\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix – Random Forest Classification\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b69dc34",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "\n",
    "The classification report summarizes performance\n",
    "for each class using:\n",
    "\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "\n",
    "These metrics help evaluate trade-offs\n",
    "between different types of errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383ca8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a6527",
   "metadata": {},
   "source": [
    "### About the confusion matrix\n",
    "\n",
    "In this notebook, we focus on interpreting the results\n",
    "produced by the confusion matrix.\n",
    "\n",
    "For a deeper explanation of:\n",
    "- how each cell should be read\n",
    "- how metrics are derived\n",
    "- practical examples\n",
    "\n",
    "please refer to the dedicated **Confusion Matrix**\n",
    "page in the general concepts section of this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb786c",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Random Forest Classification evaluation typically shows:\n",
    "- strong overall accuracy\n",
    "- balanced precision and recall\n",
    "- robustness to noise and outliers\n",
    "\n",
    "The confusion matrix remains the most informative tool\n",
    "to understand classification behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fdfd0f",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 10. When to use it and when not to (Random Forest Classification)\n",
    "\n",
    "Random Forest Classification is a powerful and versatile model,\n",
    "but it is not always the best choice.\n",
    "\n",
    "Knowing when to use it\n",
    "helps balance performance, interpretability, and efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa0ee6",
   "metadata": {},
   "source": [
    "### When Random Forest Classification is a good choice\n",
    "\n",
    "Random Forest works well when:\n",
    "\n",
    "- The relationship between features and classes is non-linear\n",
    "- The dataset contains complex interactions between features\n",
    "- Robustness to noise and outliers is important\n",
    "- You want strong performance with minimal tuning\n",
    "- Interpretability at the feature level is not critical\n",
    "\n",
    "It is often used as:\n",
    "- a strong default classifier\n",
    "- a benchmark for more advanced models\n",
    "- a production-ready model for tabular data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d7672",
   "metadata": {},
   "source": [
    "### When Random Forest Classification is NOT a good choice\n",
    "\n",
    "Random Forest may not be ideal when:\n",
    "\n",
    "- Model interpretability is a top priority\n",
    "- The dataset is extremely large and memory is limited\n",
    "- Very fast training or inference is required\n",
    "- The problem is simple and linear models already perform well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44482df",
   "metadata": {},
   "source": [
    "### Typical warning signs\n",
    "\n",
    "You should be cautious if:\n",
    "\n",
    "- The model overfits despite many trees\n",
    "- Training time becomes excessive\n",
    "- Feature importance is difficult to interpret meaningfully\n",
    "- A simpler model achieves similar performance\n",
    "\n",
    "These signs suggest that Random Forest\n",
    "may be unnecessarily complex for the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32177322",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Random Forest Classification offers an excellent balance\n",
    "between performance and robustness.\n",
    "\n",
    "It is often one of the best first choices\n",
    "for complex tabular classification problems,\n",
    "but its power comes at the cost of interpretability\n",
    "and computational efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fabb3",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 11. Model persistence (Random Forest Classification)\n",
    "\n",
    "In this section we save the trained Random Forest classifier\n",
    "and the preprocessing steps used during training.\n",
    "\n",
    "Saving the model allows us to reuse it later\n",
    "without retraining and ensures reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158cfce",
   "metadata": {},
   "source": [
    "### Why saving the model is important\n",
    "\n",
    "Once a model has been trained and evaluated,\n",
    "it is common practice to save it.\n",
    "\n",
    "This allows the model to be:\n",
    "- reused in other notebooks\n",
    "- integrated into applications\n",
    "- deployed in production systems\n",
    "\n",
    "Model persistence separates\n",
    "training from inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e96602",
   "metadata": {},
   "source": [
    "### Should we save the scaler for Random Forest?\n",
    "\n",
    "Random Forest does not depend on feature scaling.\n",
    "\n",
    "However, in this project:\n",
    "- scaling is part of the common pipeline\n",
    "- all models share the same preprocessing steps\n",
    "\n",
    "For this reason, we save the scaler together with the model\n",
    "to ensure full pipeline reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87accd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Define model directory\n",
    "model_dir = Path(\"models/supervised_learning/classification/random_forest\")\n",
    "\n",
    "# Create directory if it does not exist\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(rf_model, model_dir / \"random_forest_model.joblib\")\n",
    "joblib.dump(scaler, model_dir / \"scaler.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eeebdc",
   "metadata": {},
   "source": [
    "### What we have now\n",
    "\n",
    "- A trained Random Forest classification model\n",
    "- A fitted feature scaler\n",
    "- Both saved and ready to be reused\n",
    "\n",
    "The model can now be:\n",
    "- loaded without retraining\n",
    "- applied to new data\n",
    "- compared with other classification models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc0d59",
   "metadata": {},
   "source": [
    "### Loading the model later (conceptual example)\n",
    "\n",
    "To reuse the model:\n",
    "- load the scaler\n",
    "- apply it to new input data\n",
    "- load the Random Forest model\n",
    "- generate predictions\n",
    "\n",
    "This guarantees consistency\n",
    "with the original training pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28dcb8",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 12. Mathematical formulation (deep dive)\n",
    "\n",
    "This section provides a mathematical and algorithmic view\n",
    "of Random Forest Classification.\n",
    "\n",
    "The goal is to understand how the model works internally,\n",
    "without going into low-level implementation details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747e597",
   "metadata": {},
   "source": [
    "### Representation of the data\n",
    "\n",
    "Random Forest Classification is trained on a labeled dataset:\n",
    "\n",
    "$$\n",
    "\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x_i \\in \\mathbb{R}^d$ is a feature vector\n",
    "- $y_i \\in \\{0, 1\\}$ is the class label\n",
    "\n",
    "The model learns a collection of decision trees\n",
    "from this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf66fe",
   "metadata": {},
   "source": [
    "### Bootstrap sampling (bagging)\n",
    "\n",
    "Each decision tree in the forest\n",
    "is trained on a **bootstrap sample** of the training data.\n",
    "\n",
    "A bootstrap sample is created by:\n",
    "- randomly sampling $n$ points\n",
    "- with replacement\n",
    "- from the original training set\n",
    "\n",
    "This introduces diversity among trees\n",
    "and reduces overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc5958",
   "metadata": {},
   "source": [
    "### Decision tree splits\n",
    "\n",
    "Each decision tree recursively splits the feature space.\n",
    "\n",
    "At each node, a feature $j$ and a threshold $t$ are selected\n",
    "to maximize a purity criterion, such as:\n",
    "\n",
    "- Gini impurity\n",
    "- or entropy\n",
    "\n",
    "The goal is to partition the data\n",
    "into more homogeneous subsets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d664351e",
   "metadata": {},
   "source": [
    "### Random feature selection\n",
    "\n",
    "At each split, Random Forest considers\n",
    "only a random subset of features.\n",
    "\n",
    "This means that:\n",
    "- not all features compete at every split\n",
    "- trees become less correlated\n",
    "- ensemble performance improves\n",
    "\n",
    "This randomness is a key component\n",
    "of the Random Forest algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e43e669",
   "metadata": {},
   "source": [
    "### Tree-level prediction\n",
    "\n",
    "Each individual decision tree $T_k$\n",
    "produces a class prediction:\n",
    "\n",
    "$$\n",
    "\\hat{y}^{(k)} \\in \\{0, 1\\}\n",
    "$$\n",
    "\n",
    "This prediction is based on\n",
    "the path followed by the input sample\n",
    "from the root to a leaf node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a429a",
   "metadata": {},
   "source": [
    "### Ensemble voting\n",
    "\n",
    "The final prediction of the Random Forest\n",
    "is obtained by majority voting:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\text{mode}(\\hat{y}^{(1)}, \\hat{y}^{(2)}, \\dots, \\hat{y}^{(K)})\n",
    "$$\n",
    "\n",
    "where $K$ is the number of trees in the forest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0eb6a9",
   "metadata": {},
   "source": [
    "### Probabilistic interpretation\n",
    "\n",
    "Random Forest can also output class probabilities.\n",
    "\n",
    "The probability of a class is computed as:\n",
    "\n",
    "$$\n",
    "P(y = c \\mid x) =\n",
    "\\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{1}\n",
    "\\bigl(\\hat{y}^{(k)} = c\\bigr)\n",
    "$$\n",
    "\n",
    "This represents the fraction of trees\n",
    "predicting class $c$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697850cc",
   "metadata": {},
   "source": [
    "### Bias–variance perspective\n",
    "\n",
    "Random Forest reduces variance by:\n",
    "- averaging many high-variance decision trees\n",
    "- introducing randomness in data and features\n",
    "\n",
    "This leads to:\n",
    "- lower variance than a single tree\n",
    "- strong generalization performance\n",
    "- stable predictions across datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19e29c",
   "metadata": {},
   "source": [
    "### Final takeaway\n",
    "\n",
    "Random Forest Classification combines:\n",
    "- decision trees\n",
    "- bootstrap sampling\n",
    "- random feature selection\n",
    "- ensemble voting\n",
    "\n",
    "This results in a powerful, non-linear classifier\n",
    "that performs well on a wide range of problems,\n",
    "at the cost of reduced interpretability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855d6ef",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 13. Final summary – Code only\n",
    "\n",
    "The following cell contains the complete classification pipeline\n",
    "from data loading to model persistence.\n",
    "\n",
    "No explanations are provided here on purpose.\n",
    "\n",
    "This section is intended for:\n",
    "- quick execution\n",
    "- reference\n",
    "- reuse in scripts or applications\n",
    "\n",
    "If you want to understand what each step does and why,\n",
    "read the notebook from top to bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10131ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Imports\n",
    "# ====================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Dataset loading\n",
    "# ====================================\n",
    "\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Train-test split\n",
    "# ====================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Feature scaling (kept for consistency)\n",
    "# ====================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Model initialization\n",
    "# ====================================\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Model training\n",
    "# ====================================\n",
    "\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Predictions\n",
    "# ====================================\n",
    "\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "y_pred_proba = rf_model.predict_proba(X_test_scaled)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Model evaluation\n",
    "# ====================================\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy\n",
    "cm\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Confusion matrix visualization\n",
    "# ====================================\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=rf_model.classes_\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix – Random Forest Classification\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Model persistence\n",
    "# ====================================\n",
    "\n",
    "model_dir = Path(\"models/supervised_learning/classification/random_forest\")\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(rf_model, model_dir / \"random_forest_model.joblib\")\n",
    "joblib.dump(scaler, model_dir / \"scaler.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
