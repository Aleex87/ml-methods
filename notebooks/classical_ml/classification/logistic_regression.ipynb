{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fc19f2",
   "metadata": {},
   "source": [
    "# Supervised Learning → Logistic Regression (Classification)\n",
    "This notebook is part of the **ML-Methods** project.\n",
    "\n",
    "The first sections focus on data preparation\n",
    "and are intentionally repeated.\n",
    "\n",
    "This allows each notebook to be read independently\n",
    "and makes model comparisons clearer.\n",
    "\n",
    "1. Project setup and common pipeline\n",
    "2. Dataset loading\n",
    "3. Train-test split\n",
    "4. Feature scaling (why we do it)\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "5. What is this model? (Intuition)\n",
    "6. Model training\n",
    "7. Model behavior and key parameters\n",
    "8. Predictions\n",
    "9. Model evaluation\n",
    "10. When to use it and when not to\n",
    "11. Model persistence\n",
    "12. Mathematical formulation (deep dive)\n",
    "13. Final summary – Code only\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## How this notebook should be read\n",
    "\n",
    "This notebook is designed to be read **top to bottom**.\n",
    "\n",
    "Before every code cell, you will find a short explanation describing:\n",
    "- what we are about to do\n",
    "- why this step is necessary\n",
    "- how it fits into the overall process\n",
    "\n",
    "The goal is not just to run the code,\n",
    "but to understand what is happening at each step\n",
    "and be able to adapt it to your own data.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What is Logistic Regression?\n",
    "\n",
    "Logistic Regression is a **classification model**,\n",
    "even though its name contains the word “regression”.\n",
    "\n",
    "Instead of predicting a continuous value,\n",
    "Logistic Regression predicts the **probability**\n",
    "that an input belongs to a given class.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## Why we start with intuition\n",
    "\n",
    "Logistic Regression looks similar to Linear Regression,\n",
    "but it behaves very differently.\n",
    "\n",
    "Understanding this difference early\n",
    "helps avoid confusion when reading the code\n",
    "and interpreting the results.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What you should expect from the results\n",
    "\n",
    "With Logistic Regression, you should expect:\n",
    "- probabilistic outputs\n",
    "- linear decision boundaries\n",
    "- strong performance on linearly separable data\n",
    "\n",
    "It is often used as:\n",
    "- a baseline classification model\n",
    "- a simple and interpretable solution\n",
    "- a reference point for more complex classifiers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c35667",
   "metadata": {},
   "source": [
    "____________________________________________________\n",
    "\n",
    "## 1. Project setup and common pipeline\n",
    "\n",
    "In this section we set up the common pipeline\n",
    "used across classification models in this project.\n",
    "\n",
    "Although the pipeline is similar to regression,\n",
    "the evaluation and interpretation steps will differ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537b6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports used across all classification models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bbf2fb",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 2. Dataset loading\n",
    "\n",
    "In this section we load the dataset\n",
    "used for the Logistic Regression classification task.\n",
    "\n",
    "We use a binary classification dataset\n",
    "to clearly illustrate how the model works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52aab1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b4136",
   "metadata": {},
   "source": [
    "### Inputs and target\n",
    "\n",
    "- `X` contains the input features\n",
    "- `y` contains the target labels\n",
    "\n",
    "In this dataset:\n",
    "- the task is binary classification\n",
    "- the target takes two possible values (0 or 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5aab9f",
   "metadata": {},
   "source": [
    "### Why this dataset is suitable\n",
    "\n",
    "This dataset is well suited for Logistic Regression because:\n",
    "- it is clean and well-structured\n",
    "- the classes are reasonably separable\n",
    "- it is commonly used as a reference for classification models\n",
    "\n",
    "This makes it ideal for understanding\n",
    "both the strengths and limitations of Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62060e1e",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 3. Train-test split\n",
    "\n",
    "In this section we split the dataset\n",
    "into training and test sets.\n",
    "\n",
    "This step is essential to evaluate\n",
    "how well the classification model generalizes\n",
    "to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d70a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b7979f",
   "metadata": {},
   "source": [
    "### Why this step is important\n",
    "\n",
    "A classification model should be evaluated\n",
    "on data it has never seen before.\n",
    "\n",
    "By separating the data:\n",
    "- the training set is used to learn decision boundaries\n",
    "- the test set is used only for evaluation\n",
    "\n",
    "This prevents overly optimistic results\n",
    "and reflects real-world performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be9c94",
   "metadata": {},
   "source": [
    "### Consistency across notebooks\n",
    "\n",
    "We use the same split strategy\n",
    "as in other ML-Methods notebooks.\n",
    "\n",
    "This keeps the pipeline consistent\n",
    "and makes comparisons across models easier.\n",
    "\n",
    "### Note on train-test split proportions\n",
    "\n",
    "The choice of train-test split proportions\n",
    "depends on the specific problem and dataset.\n",
    "\n",
    "Common splits include:\n",
    "- 80 / 20\n",
    "- 70 / 30\n",
    "- 90 / 10\n",
    "\n",
    "In this notebook, we use an 80 / 20 split\n",
    "as a reasonable default.\n",
    "\n",
    "In practice:\n",
    "- smaller datasets may benefit from more training data\n",
    "- larger datasets allow for larger test sets\n",
    "- cross-validation is often used for more robust evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75208a61",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 4. Feature scaling (why we do it)\n",
    "\n",
    "In this section we apply feature scaling\n",
    "to the input features.\n",
    "\n",
    "Feature scaling is **very important** for Logistic Regression\n",
    "and directly affects how the model learns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf41648",
   "metadata": {},
   "source": [
    "### Why scaling matters for Logistic Regression\n",
    "\n",
    "Logistic Regression is an optimization-based model.\n",
    "\n",
    "This means:\n",
    "- the model learns parameters by minimizing a loss function\n",
    "- gradient-based optimization is used\n",
    "\n",
    "If features have very different scales:\n",
    "- optimization becomes slower\n",
    "- some features may dominate others\n",
    "- convergence may be unstable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a9f7a3",
   "metadata": {},
   "source": [
    "### What scaling does\n",
    "\n",
    "Feature scaling:\n",
    "- centers features around zero\n",
    "- puts them on a comparable scale\n",
    "- improves numerical stability\n",
    "\n",
    "This helps the model:\n",
    "- learn faster\n",
    "- converge more reliably\n",
    "- produce more stable coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ddc396",
   "metadata": {},
   "source": [
    "### Important rule: fit only on training data\n",
    "\n",
    "As with all preprocessing steps:\n",
    "- the scaler is fitted on training data only\n",
    "- the same scaler is applied to test data\n",
    "\n",
    "This prevents data leakage\n",
    "and ensures a fair evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd0b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f8d90",
   "metadata": {},
   "source": [
    "### What we have after this step\n",
    "\n",
    "- scaled training data\n",
    "- scaled test data\n",
    "- a clean and stable input space for Logistic Regression\n",
    "\n",
    "At this point, the data is ready\n",
    "to be used by the classification model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93528d7f",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 5. What is this model? (Logistic Regression)\n",
    "\n",
    "Before training the model, it is important to understand\n",
    "what Logistic Regression does conceptually.\n",
    "\n",
    "Despite its name, Logistic Regression is **not a regression model**.\n",
    "It is a **classification model**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8aeb8",
   "metadata": {},
   "source": [
    "### The core idea\n",
    "\n",
    "Logistic Regression predicts **probabilities**, not class labels.\n",
    "\n",
    "Given an input sample, the model computes:\n",
    "- a score based on a linear combination of the features\n",
    "- transforms this score into a probability between 0 and 1\n",
    "\n",
    "This probability represents:\n",
    "- how likely the sample belongs to a given class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5c4d4",
   "metadata": {},
   "source": [
    "### From probability to class\n",
    "\n",
    "To make a final classification decision:\n",
    "- a threshold is applied (usually 0.5)\n",
    "- probabilities above the threshold are assigned to class 1\n",
    "- probabilities below the threshold are assigned to class 0\n",
    "\n",
    "This simple rule converts probabilities\n",
    "into discrete class predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35ec8c",
   "metadata": {},
   "source": [
    "### How this differs from Linear Regression\n",
    "\n",
    "Linear Regression:\n",
    "- predicts continuous values\n",
    "- has no concept of probability\n",
    "- is not suitable for classification\n",
    "\n",
    "Logistic Regression:\n",
    "- predicts probabilities\n",
    "- is designed for classification\n",
    "- produces a decision boundary between classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781168e",
   "metadata": {},
   "source": [
    "### Why the sigmoid function matters\n",
    "\n",
    "Logistic Regression uses a **sigmoid function**\n",
    "to map any real-valued number\n",
    "into a value between 0 and 1.\n",
    "\n",
    "This ensures that:\n",
    "- predictions can be interpreted as probabilities\n",
    "- extreme values are smoothly compressed\n",
    "- the model remains stable during training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2307d0",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Logistic Regression answers the question:\n",
    "\"What is the probability that this sample belongs to class 1?\"\n",
    "\n",
    "By combining a linear model with a probability function,\n",
    "it provides a simple, interpretable, and effective\n",
    "approach to binary classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e65e6c4",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 6. Model training (Logistic Regression)\n",
    "\n",
    "In this section we train the Logistic Regression model.\n",
    "\n",
    "Training Logistic Regression means learning\n",
    "a linear decision boundary that separates the classes\n",
    "by optimizing a probabilistic loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cedcb0",
   "metadata": {},
   "source": [
    "### What does \"training\" mean for Logistic Regression?\n",
    "\n",
    "During training, the model:\n",
    "- computes predicted probabilities\n",
    "- compares them with the true class labels\n",
    "- updates its parameters to reduce the prediction error\n",
    "\n",
    "This process is performed using\n",
    "gradient-based optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc45a41",
   "metadata": {},
   "source": [
    "### Important parameters (kept simple)\n",
    "\n",
    "For this first example, we use a basic configuration.\n",
    "\n",
    "The goal is to understand how the model works,\n",
    "not to optimize its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2945d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m log_reg_model = LogisticRegression(\n\u001b[32m      5\u001b[39m     max_iter=\u001b[32m1000\u001b[39m,\n\u001b[32m      6\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m log_reg_model.fit(\u001b[43mX_train_scaled\u001b[49m, y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "log_reg_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "log_reg_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de6ca5",
   "metadata": {},
   "source": [
    "### What these parameters mean\n",
    "\n",
    "- `max_iter=1000`  \n",
    "  Maximum number of optimization iterations.  \n",
    "  Increased to ensure convergence after feature scaling.\n",
    "\n",
    "- `random_state=42`  \n",
    "  Ensures reproducibility of results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c886eb89",
   "metadata": {},
   "source": [
    "Note:\n",
    "The `max_iter` parameter does not affect model complexity.\n",
    "It only ensures that the optimization process\n",
    "has enough iterations to converge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5c012",
   "metadata": {},
   "source": [
    "### What we have after training\n",
    "\n",
    "After this step:\n",
    "- the model has learned a decision boundary\n",
    "- coefficients define how features influence the prediction\n",
    "- the model is ready to output probabilities and class labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908a5b0",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 7. Model behavior and key parameters (Logistic Regression)\n",
    "\n",
    "In this section we analyze how Logistic Regression behaves\n",
    "and which parameters influence its predictions.\n",
    "\n",
    "Unlike regression models,\n",
    "Logistic Regression produces probabilities\n",
    "and class decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a73b800",
   "metadata": {},
   "source": [
    "### Coefficients and feature influence\n",
    "\n",
    "Logistic Regression learns one coefficient per feature.\n",
    "\n",
    "Each coefficient represents:\n",
    "- the strength of the feature\n",
    "- the direction of its influence on the predicted probability\n",
    "\n",
    "Positive coefficients:\n",
    "- increase the probability of class 1\n",
    "\n",
    "Negative coefficients:\n",
    "- decrease the probability of class 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187cb81",
   "metadata": {},
   "source": [
    "### Decision boundary\n",
    "\n",
    "Logistic Regression creates a **linear decision boundary**.\n",
    "\n",
    "This boundary separates:\n",
    "- samples predicted as class 0\n",
    "- samples predicted as class 1\n",
    "\n",
    "Even though the output is probabilistic,\n",
    "the boundary itself is linear in the feature space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d416177",
   "metadata": {},
   "source": [
    "### Probability vs class prediction\n",
    "\n",
    "The model internally works with probabilities.\n",
    "\n",
    "To produce class labels:\n",
    "- a threshold is applied (usually 0.5)\n",
    "- probabilities above the threshold → class 1\n",
    "- probabilities below the threshold → class 0\n",
    "\n",
    "Changing this threshold changes:\n",
    "- the balance between false positives and false negatives in te confusion matrix. We will see that soon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428eca0",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Logistic Regression:\n",
    "- models probabilities, not just labels\n",
    "- uses a linear decision boundary\n",
    "- is highly interpretable\n",
    "\n",
    "To properly evaluate its performance,\n",
    "we need more than a single metric.\n",
    "\n",
    "This is why, in the evaluation step,\n",
    "we will use a **confusion matrix**\n",
    "to understand different types of errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd4ce18",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 8. Predictions (Logistic Regression)\n",
    "\n",
    "In this section we use the trained Logistic Regression model\n",
    "to generate predictions on unseen data.\n",
    "\n",
    "For classification models,\n",
    "it is important to distinguish between:\n",
    "- predicted probabilities\n",
    "- predicted class labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a4f75",
   "metadata": {},
   "source": [
    "### Predicting class labels\n",
    "\n",
    "The `predict` method returns the final class prediction.\n",
    "\n",
    "These predictions are obtained by:\n",
    "- computing probabilities internally\n",
    "- applying a decision threshold (default = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "121259a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict class labels on the test set\n",
    "\n",
    "y_pred = log_reg_model.predict(X_test_scaled)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad001295",
   "metadata": {},
   "source": [
    "### Predicting probabilities\n",
    "\n",
    "The `predict_proba` method returns class probabilities.\n",
    "\n",
    "For each sample, it outputs:\n",
    "- the probability of class 0\n",
    "- the probability of class 1\n",
    "\n",
    "These probabilities provide more information\n",
    "than class labels alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1680502b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(class 0)</th>\n",
       "      <th>P(class 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.113590</td>\n",
       "      <td>8.864098e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>9.009362e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996921</td>\n",
       "      <td>3.079095e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000510</td>\n",
       "      <td>9.994899e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>9.999394e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.480878e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.536726e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.965097</td>\n",
       "      <td>3.490306e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.379342</td>\n",
       "      <td>6.206579e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000759</td>\n",
       "      <td>9.992406e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P(class 0)    P(class 1)\n",
       "0    0.113590  8.864098e-01\n",
       "1    0.999991  9.009362e-06\n",
       "2    0.996921  3.079095e-03\n",
       "3    0.000510  9.994899e-01\n",
       "4    0.000061  9.999394e-01\n",
       "5    1.000000  9.480878e-11\n",
       "6    1.000000  1.536726e-09\n",
       "7    0.965097  3.490306e-02\n",
       "8    0.379342  6.206579e-01\n",
       "9    0.000759  9.992406e-01"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict class probabilities on the test set\n",
    "\n",
    "y_pred_proba = log_reg_model.predict_proba(X_test_scaled)\n",
    "\n",
    "pd.DataFrame(\n",
    "    y_pred_proba[:10],\n",
    "    columns=[\"P(class 0)\", \"P(class 1)\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a42092",
   "metadata": {},
   "source": [
    "### How probabilities are used\n",
    "\n",
    "Probabilities allow us to:\n",
    "- understand model confidence\n",
    "- adjust the classification threshold\n",
    "- analyze different types of errors\n",
    "\n",
    "In this notebook:\n",
    "- we use the default threshold (0.5)\n",
    "- probabilities are used for interpretation,\n",
    "  not for threshold tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3ce6f",
   "metadata": {},
   "source": [
    "### What you should expect to see\n",
    "\n",
    "With Logistic Regression, you should expect:\n",
    "- confident predictions for well-separated samples\n",
    "- probabilities closer to 0.5 near the decision boundary\n",
    "- stable and interpretable behavior\n",
    "\n",
    "These predictions will be evaluated in the next section\n",
    "using appropriate classification metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099002e",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 9. Model evaluation (Logistic Regression)\n",
    "\n",
    "In this section we evaluate the performance of the Logistic Regression model\n",
    "on unseen test data.\n",
    "\n",
    "For classification problems, evaluation is not limited\n",
    "to a single metric.\n",
    "We need to understand **what type of errors** the model makes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68caecbe",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Accuracy measures the proportion of correct predictions.\n",
    "\n",
    "It answers the question:\n",
    "\"How often is the model correct?\"\n",
    "\n",
    "While useful, accuracy alone can be misleading,\n",
    "especially when classes are imbalanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de383a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"accuracy :{accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba959f",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "The confusion matrix provides a detailed breakdown\n",
    "of prediction results.\n",
    "\n",
    "It shows:\n",
    "- correct predictions\n",
    "- false positives\n",
    "- false negatives\n",
    "\n",
    "This allows us to understand *how* the model is making mistakes,\n",
    "not just how many.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d87b83be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41,  2],\n",
       "       [ 1, 70]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6a695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize confusion matrix\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=log_reg_model.classes_\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix – Logistic Regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a8a6e",
   "metadata": {},
   "source": [
    "### About the confusion matrix\n",
    "\n",
    "The confusion matrix provides a detailed view\n",
    "of how a classification model makes predictions.\n",
    "\n",
    "In this notebook, we focus on **how to read the results**\n",
    "and what they tell us about model behavior.\n",
    "\n",
    "For a deeper explanation of:\n",
    "- each cell of the matrix\n",
    "- common pitfalls\n",
    "- real-world examples\n",
    "\n",
    "please refer to the dedicated **Confusion Matrix** page\n",
    "in the general concepts section of this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1ce7b",
   "metadata": {},
   "source": [
    "### How to read the confusion matrix\n",
    "\n",
    "For a binary classification problem:\n",
    "\n",
    "- True Negatives (top-left):\n",
    "  correctly predicted class 0\n",
    "\n",
    "- False Positives (top-right):\n",
    "  predicted class 1, but true class is 0\n",
    "\n",
    "- False Negatives (bottom-left):\n",
    "  predicted class 0, but true class is 1\n",
    "\n",
    "- True Positives (bottom-right):\n",
    "  correctly predicted class 1\n",
    "\n",
    "Each cell tells us a different story\n",
    "about model behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def281f",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "\n",
    "The classification report summarizes key metrics\n",
    "for each class:\n",
    "\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "\n",
    "These metrics are especially important\n",
    "when the cost of different errors is not the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd55f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aae3ed",
   "metadata": {},
   "source": [
    "### What you should focus on\n",
    "\n",
    "When evaluating Logistic Regression:\n",
    "\n",
    "- Accuracy gives a high-level overview\n",
    "- Confusion matrix shows error types\n",
    "- Precision and recall explain trade-offs\n",
    "\n",
    "There is no single “best” metric.\n",
    "The right focus depends on the problem context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8f697",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Logistic Regression evaluation is about understanding errors,\n",
    "not just counting correct predictions.\n",
    "\n",
    "The confusion matrix is the most informative tool\n",
    "to analyze classification performance\n",
    "and should always be examined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75cdab",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 10. When to use it and when not to (Logistic Regression)\n",
    "\n",
    "Logistic Regression is a simple and effective classification model,\n",
    "but it is not suitable for every problem.\n",
    "\n",
    "Understanding when to use it\n",
    "helps avoid incorrect assumptions and poor performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b9ecb",
   "metadata": {},
   "source": [
    "### When Logistic Regression is a good choice\n",
    "\n",
    "Logistic Regression works well when:\n",
    "\n",
    "- The task is binary classification\n",
    "- Classes are approximately linearly separable\n",
    "- Interpretability is important\n",
    "- You need a fast and reliable baseline model\n",
    "- Probabilistic outputs are useful\n",
    "\n",
    "It is often used as:\n",
    "- a first classification model\n",
    "- a benchmark for more complex classifiers\n",
    "- a transparent solution in regulated environments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f845a7",
   "metadata": {},
   "source": [
    "### When Logistic Regression is NOT a good choice\n",
    "\n",
    "Logistic Regression may struggle when:\n",
    "\n",
    "- The relationship between features and classes is highly non-linear\n",
    "- Complex interactions between features are important\n",
    "- The number of features is very large compared to samples\n",
    "- Maximum predictive performance is required regardless of interpretability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bbfc85",
   "metadata": {},
   "source": [
    "### Typical warning signs\n",
    "\n",
    "You should be cautious if:\n",
    "\n",
    "- Accuracy is high but confusion matrix shows poor recall for a class\n",
    "- Many samples lie close to the decision boundary\n",
    "- Performance is significantly worse than non-linear models\n",
    "\n",
    "These signs indicate that a linear decision boundary\n",
    "may be too restrictive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58daf8f",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Logistic Regression is valued for:\n",
    "- simplicity\n",
    "- interpretability\n",
    "- probabilistic outputs\n",
    "\n",
    "It is rarely the final model in complex problems,\n",
    "but it is almost always a useful starting point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4062b8c3",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 11. Model persistence (Logistic Regression)\n",
    "\n",
    "In this section we save the trained Logistic Regression model\n",
    "and the preprocessing steps used during training.\n",
    "\n",
    "Saving the model allows us to reuse it later\n",
    "without retraining and ensures reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cab595",
   "metadata": {},
   "source": [
    "### Why saving the model is important\n",
    "\n",
    "Once a classification model has been trained and evaluated,\n",
    "it is common practice to save it.\n",
    "\n",
    "This allows the model to be:\n",
    "- reused in another notebook\n",
    "- integrated into an application\n",
    "- deployed in a production environment\n",
    "\n",
    "Model persistence separates\n",
    "the training phase from the usage phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b55a4",
   "metadata": {},
   "source": [
    "### Important rule: save the scaler together with the model\n",
    "\n",
    "Logistic Regression is sensitive to feature scaling.\n",
    "\n",
    "For this reason:\n",
    "- the same scaler used during training\n",
    "- must be applied to any new input data\n",
    "\n",
    "Saving the scaler together with the model\n",
    "ensures consistent predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f4f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\supervised_learning\\\\classification\\\\logistic_regression\\\\scaler.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model directory\n",
    "model_dir = Path(\"models/supervised_learning/classification/logistic_regression\")\n",
    "\n",
    "# Create directory if it does not exist\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(log_reg_model, model_dir / \"logistic_regression_model.joblib\")\n",
    "joblib.dump(scaler, model_dir / \"scaler.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f01f9",
   "metadata": {},
   "source": [
    "### What we have now\n",
    "\n",
    "- A trained Logistic Regression classification model\n",
    "- A fitted feature scaler\n",
    "- Both saved and ready to be reused\n",
    "\n",
    "At this point, the model can be:\n",
    "- loaded without retraining\n",
    "- applied to new data\n",
    "- compared with other saved classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f36af",
   "metadata": {},
   "source": [
    "### Loading the model later (conceptual example)\n",
    "\n",
    "To reuse the model:\n",
    "- load the scaler\n",
    "- scale new input data\n",
    "- load the Logistic Regression model\n",
    "- generate predictions\n",
    "\n",
    "This guarantees consistency\n",
    "with the original training pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8140152",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 12. Mathematical formulation (deep dive)\n",
    "\n",
    "This section provides a deeper look at Logistic Regression\n",
    "from a mathematical perspective.\n",
    "\n",
    "The goal is to understand the mechanism behind the model,\n",
    "not to derive formulas in full detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa66bea",
   "metadata": {},
   "source": [
    "### From linear model to classification\n",
    "\n",
    "Logistic Regression starts from a linear model.\n",
    "\n",
    "Given an input vector x, the model computes:\n",
    "- a weighted sum of the features\n",
    "- plus an intercept term\n",
    "\n",
    "This produces a real-valued score,\n",
    "which by itself is not suitable for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030961eb",
   "metadata": {},
   "source": [
    "### The role of the sigmoid function\n",
    "\n",
    "To convert the linear score into a probability,\n",
    "Logistic Regression applies the **sigmoid function**.\n",
    "\n",
    "The sigmoid:\n",
    "- maps any real number to a value between 0 and 1\n",
    "- ensures outputs can be interpreted as probabilities\n",
    "- smoothly compresses extreme values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc45527f",
   "metadata": {},
   "source": [
    "### Probabilistic interpretation\n",
    "\n",
    "The output of Logistic Regression represents:\n",
    "\n",
    "- the probability that a sample belongs to class 1\n",
    "\n",
    "This probabilistic formulation allows:\n",
    "- uncertainty estimation\n",
    "- threshold-based decision making\n",
    "- flexible interpretation of predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ee216",
   "metadata": {},
   "source": [
    "### Loss function and optimization\n",
    "\n",
    "Logistic Regression is trained by minimizing\n",
    "the **log-loss** (also called cross-entropy loss).\n",
    "\n",
    "This loss:\n",
    "- penalizes confident wrong predictions heavily\n",
    "- rewards confident correct predictions\n",
    "- encourages well-calibrated probabilities\n",
    "\n",
    "The optimization is performed iteratively\n",
    "using gradient-based methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa0575",
   "metadata": {},
   "source": [
    "### Decision boundary\n",
    "\n",
    "The decision boundary of Logistic Regression is linear.\n",
    "\n",
    "It corresponds to:\n",
    "- the set of points where the predicted probability is 0.5\n",
    "\n",
    "Even though probabilities are non-linear,\n",
    "the boundary itself remains linear in the feature space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe67fb8",
   "metadata": {},
   "source": [
    "### Regularization (conceptual view)\n",
    "\n",
    "Regularization adds a penalty to the loss function\n",
    "to control model complexity.\n",
    "\n",
    "Its effects include:\n",
    "- preventing overly large coefficients\n",
    "- improving generalization\n",
    "- reducing overfitting\n",
    "\n",
    "In this notebook, default regularization is used\n",
    "to keep the focus on model understanding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076655ed",
   "metadata": {},
   "source": [
    "### Final takeaway\n",
    "\n",
    "Logistic Regression combines:\n",
    "- a linear model\n",
    "- a probabilistic interpretation\n",
    "- an optimization-based training process\n",
    "\n",
    "This makes it:\n",
    "- simple yet powerful\n",
    "- interpretable\n",
    "- a strong baseline for classification problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eecda7",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## Final summary – Code only\n",
    "\n",
    "The following cell contains the complete classification pipeline\n",
    "from data loading to model persistence.\n",
    "\n",
    "No explanations are provided here on purpose.\n",
    "\n",
    "This section is intended for:\n",
    "- quick execution\n",
    "- reference\n",
    "- reuse in scripts or applications\n",
    "\n",
    "If you want to understand what each step does and why,\n",
    "read the notebook from top to bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Imports\n",
    "# ====================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Dataset loading\n",
    "# ====================================\n",
    "\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Train-test split\n",
    "# ====================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Feature scaling\n",
    "# ====================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Model initialization\n",
    "# ====================================\n",
    "\n",
    "log_reg_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Model training\n",
    "# ====================================\n",
    "\n",
    "log_reg_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Predictions\n",
    "# ====================================\n",
    "\n",
    "y_pred = log_reg_model.predict(X_test_scaled)\n",
    "y_pred_proba = log_reg_model.predict_proba(X_test_scaled)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Model evaluation\n",
    "# ====================================\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy\n",
    "cm\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Confusion matrix visualization\n",
    "# ====================================\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=log_reg_model.classes_\n",
    ")\n",
    "\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix – Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# Model persistence\n",
    "# ====================================\n",
    "\n",
    "model_dir = Path(\"models/supervised_learning/classification/logistic_regression\")\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(log_reg_model, model_dir / \"logistic_regression_model.joblib\")\n",
    "joblib.dump(scaler, model_dir / \"scaler.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
