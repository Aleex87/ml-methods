{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbd26f1",
   "metadata": {},
   "source": [
    "# Deep Learning – Classification (PyTorch)\n",
    "\n",
    "This notebook is part of the **ML-Methods** project.\n",
    "\n",
    "It introduces **Deep Learning for supervised classification**\n",
    "using **PyTorch**, a low-level and flexible deep learning framework.\n",
    "\n",
    "As with the other classification notebooks,\n",
    "the first sections focus on data preparation\n",
    "and are intentionally repeated.\n",
    "\n",
    "This ensures consistency across models\n",
    "and allows fair comparison of results.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## Notebook Roadmap (standard ML-Methods)\n",
    "\n",
    "1. Project setup and common pipeline  \n",
    "2. Dataset loading  \n",
    "3. Train-test split  \n",
    "4. Feature scaling (why we do it)  \n",
    "\n",
    "----------------------------------\n",
    "\n",
    "5. What is this model? (Intuition)  \n",
    "6. Model training  \n",
    "7. Model behavior and key parameters  \n",
    "8. Predictions  \n",
    "9. Model evaluation  \n",
    "10. When to use it and when not to  \n",
    "11. Model persistence  \n",
    "12. Mathematical formulation (deep dive)  \n",
    "13. Final summary – Code only  \n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## How this notebook should be read\n",
    "\n",
    "This notebook is designed to be read **top to bottom**.\n",
    "\n",
    "Before every code cell, you will find a short explanation describing:\n",
    "- what we are about to do\n",
    "- why this step is necessary\n",
    "- how it fits into the overall process\n",
    "\n",
    "Compared to scikit-learn,\n",
    "this notebook exposes **more internal details**\n",
    "of how a Deep Learning model is trained.\n",
    "\n",
    "The goal is not only to run the code,\n",
    "but to understand **what happens during training**\n",
    "and how neural networks learn step by step.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What is Deep Learning (in this context)?\n",
    "\n",
    "Deep Learning refers to a class of models\n",
    "based on **neural networks with multiple layers**.\n",
    "\n",
    "These models are designed to:\n",
    "- learn complex, non-linear relationships\n",
    "- build internal representations of the data\n",
    "- improve performance as data complexity increases\n",
    "\n",
    "In this notebook, we focus on:\n",
    "**Deep Learning for tabular classification**\n",
    "using fully connected neural networks.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## Why PyTorch?\n",
    "\n",
    "PyTorch is a **low-level deep learning framework**\n",
    "that provides explicit control over:\n",
    "\n",
    "- model architecture\n",
    "- forward pass\n",
    "- loss computation\n",
    "- backpropagation\n",
    "- parameter updates\n",
    "\n",
    "Unlike scikit-learn:\n",
    "- nothing is hidden\n",
    "- every step must be defined explicitly\n",
    "\n",
    "This makes PyTorch ideal for:\n",
    "- learning how neural networks actually work\n",
    "- understanding gradient-based optimization\n",
    "- experimenting with custom architectures\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## Execution model: eager execution\n",
    "\n",
    "PyTorch uses **eager execution** by default.\n",
    "\n",
    "This means:\n",
    "- operations are executed immediately\n",
    "- tensors behave like regular Python objects\n",
    "- debugging is straightforward\n",
    "\n",
    "Eager execution makes PyTorch:\n",
    "- intuitive to learn\n",
    "- flexible to experiment with\n",
    "- closer to the mathematical description of the model\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What you should expect from the results\n",
    "\n",
    "With Deep Learning (PyTorch), you should expect:\n",
    "\n",
    "- non-linear decision boundaries\n",
    "- strong performance on complex data\n",
    "- behavior similar to scikit-learn neural networks\n",
    "- higher transparency during training\n",
    "\n",
    "However:\n",
    "- more code is required\n",
    "- implementation errors are easier to make\n",
    "- careful design is necessary\n",
    "\n",
    "-----------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa43a78",
   "metadata": {},
   "source": [
    "## 1. Project setup and common pipeline\n",
    "\n",
    "In this section we set up the common pipeline\n",
    "used across classification models in this project.\n",
    "\n",
    "Although this notebook uses **PyTorch**,\n",
    "the overall workflow remains identical\n",
    "to the scikit-learn Deep Learning notebook.\n",
    "\n",
    "This allows us to:\n",
    "- reuse the same data preparation steps\n",
    "- compare models fairly\n",
    "- isolate the effect of the framework choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2856c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports used across classification models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================================\n",
    "# PyTorch imports\n",
    "# ====================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d10527",
   "metadata": {},
   "source": [
    "### What changes with PyTorch\n",
    "\n",
    "Compared to scikit-learn:\n",
    "- the pipeline structure remains the same\n",
    "- data preparation and evaluation stay unchanged\n",
    "- only the model implementation differs\n",
    "\n",
    "With PyTorch, we explicitly define:\n",
    "- how the model processes the input\n",
    "- how the loss is computed\n",
    "- how parameters are updated\n",
    "\n",
    "Nothing is hidden.\n",
    "\n",
    "Every step of the learning process\n",
    "is written manually in code.\n",
    "\n",
    "This makes PyTorch ideal\n",
    "for understanding what neural networks\n",
    "are actually doing during training.\n",
    "\n",
    "In the next section,\n",
    "we will load the dataset\n",
    "and prepare it for PyTorch training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993fc4d9",
   "metadata": {},
   "source": [
    "____________\n",
    "## 2. Dataset loading\n",
    "\n",
    "In this section we load the dataset\n",
    "used for the Deep Learning classification task.\n",
    "\n",
    "We intentionally use the **same dataset**\n",
    "adopted in previous classification notebooks.\n",
    "\n",
    "This ensures:\n",
    "- direct comparison with classical ML models\n",
    "- fair comparison across deep learning frameworks\n",
    "- focus on implementation differences, not on data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
