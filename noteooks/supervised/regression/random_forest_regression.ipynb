{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d5f668",
   "metadata": {},
   "source": [
    "# Supervised Learning → Random Forest Regression\n",
    "\n",
    "As with other regression models in this project,\n",
    "the first sections focus on data preparation\n",
    "and are intentionally repeated.\n",
    "\n",
    "This ensures that each notebook can be read\n",
    "and used independently, without external references.\n",
    "\n",
    "1. Project setup and common pipeline\n",
    "2. Dataset loading\n",
    "3. Train-test split\n",
    "4. Feature scaling (why we do it)\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "5. What is this model? (Intuition)\n",
    "6. Model training\n",
    "7. Model behavior and key hyperparameters\n",
    "8. Predictions\n",
    "9. Model evaluation\n",
    "10. When to use it and when not to\n",
    "11. Model persistence\n",
    "12. Mathematical formulation (deep dive)\n",
    "-----------------------------------------------------\n",
    "\n",
    "## How this notebook should be read\n",
    "\n",
    "This notebook is designed to be read **top to bottom**.\n",
    "\n",
    "Before every code cell, you will find a short explanation describing:\n",
    "- what we are about to do\n",
    "- why this step is necessary\n",
    "- how it fits into the overall process\n",
    "\n",
    "The goal is not just to run the code,\n",
    "but to understand what is happening at each step\n",
    "and be able to adapt it to your own data.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What is Random Forest Regression?\n",
    "\n",
    "Random Forest Regression is a powerful and flexible model\n",
    "that works very differently from both Linear Regression and KNN.\n",
    "\n",
    "Instead of learning a single global rule\n",
    "or relying on nearby data points,\n",
    "Random Forest builds **many decision trees**\n",
    "and combines their predictions.\n",
    "\n",
    "Each tree:\n",
    "- looks at the data in a slightly different way\n",
    "- makes its own prediction\n",
    "\n",
    "The final prediction is obtained by:\n",
    "- averaging the predictions of all trees\n",
    "\n",
    "By combining many simple models,\n",
    "Random Forest is able to capture complex and non-linear patterns\n",
    "that simpler models cannot.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## Why we start with intuition\n",
    "\n",
    "Random Forest can look complex at first,\n",
    "but the core idea is simple.\n",
    "\n",
    "Instead of trusting a single model,\n",
    "Random Forest asks the same question many times,\n",
    "each time with a slightly different perspective.\n",
    "\n",
    "Each tree may make mistakes,\n",
    "but when many trees agree,\n",
    "the final prediction becomes more reliable.\n",
    "\n",
    "Understanding this idea of **many weak models working together**\n",
    "is key to understanding how Random Forest works.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What you should expect from the results\n",
    "\n",
    "Before using Random Forest Regression,\n",
    "it is important to set expectations.\n",
    "\n",
    "With Random Forest Regression, you should expect:\n",
    "- strong performance on complex and non-linear data\n",
    "- robust predictions even in the presence of noise\n",
    "- less sensitivity to individual outliers\n",
    "\n",
    "Compared to simpler models:\n",
    "- Random Forest usually outperforms Linear Regression\n",
    "- it is more stable than KNN on large datasets\n",
    "- it requires less manual feature engineering\n",
    "\n",
    "However, this power comes at a cost:\n",
    "- the model is harder to interpret\n",
    "- training and prediction are more computationally expensive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219ae89",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 1. Project setup and common pipeline\n",
    "\n",
    "In this section we set up the common pipeline\n",
    "used across all regression models in this project.\n",
    "\n",
    "This part of the notebook does not depend on the model itself\n",
    "and is intentionally kept consistent to:\n",
    "- ensure fair comparison between models\n",
    "- reduce implementation errors\n",
    "- focus on understanding model behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7bad044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35aaab",
   "metadata": {},
   "source": [
    "### Note on feature scaling for Random Forest\n",
    "\n",
    "Random Forest does **not rely on distances**\n",
    "or linear combinations of features.\n",
    "\n",
    "For this reason, feature scaling is **not required**\n",
    "for the model to work correctly.\n",
    "\n",
    "However, we keep feature scaling in the pipeline to:\n",
    "- maintain consistency across all regression notebooks\n",
    "- simplify comparisons between models\n",
    "- avoid changing preprocessing steps when switching models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9974e54c",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 2. Dataset loading\n",
    "\n",
    "In this section we load the dataset that will be used\n",
    "to train and evaluate the Random Forest Regression model.\n",
    "\n",
    "We use the same dataset as in the other regression notebooks\n",
    "to allow direct comparison between different models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d39bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5988fe",
   "metadata": {},
   "source": [
    "### Inputs and target\n",
    "\n",
    "- `X` contains the input features\n",
    "- `y` contains the continuous target variable\n",
    "\n",
    "At this stage:\n",
    "- no modeling is performed\n",
    "- we are only defining what the model will learn from\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347d6c5",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 3. Train-test split\n",
    "\n",
    "In this section we split the dataset into\n",
    "training and test sets.\n",
    "\n",
    "This allows us to evaluate how well the model\n",
    "generalizes to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a1e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688d2fd3",
   "metadata": {},
   "source": [
    "### Why this step is important\n",
    "\n",
    "A model should not be evaluated on the same data\n",
    "it was trained on.\n",
    "\n",
    "By separating the data:\n",
    "- the training set is used to build the model\n",
    "- the test set is used only for evaluation\n",
    "\n",
    "This ensures that performance metrics\n",
    "reflect real-world behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e03eb",
   "metadata": {},
   "source": [
    "### Consistency across models\n",
    "\n",
    "We use the same split configuration\n",
    "as in the other regression notebooks.\n",
    "\n",
    "This guarantees that performance differences\n",
    "are due to the model itself\n",
    "and not to different data splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f1dc10",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 4. Feature scaling (pipeline consistency)\n",
    "\n",
    "In this section we apply feature scaling\n",
    "to the input features.\n",
    "\n",
    "Although Random Forest does not rely on distances\n",
    "or linear combinations of features,\n",
    "we keep feature scaling in the pipeline\n",
    "to maintain consistency across models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d51c852",
   "metadata": {},
   "source": [
    "### Is feature scaling required for Random Forest?\n",
    "\n",
    "Strictly speaking:\n",
    "- Random Forest **does not require** feature scaling\n",
    "\n",
    "Decision trees:\n",
    "- split features based on thresholds\n",
    "- are invariant to feature scale\n",
    "\n",
    "However, scaling is still applied here\n",
    "for consistency and comparability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e0fe8",
   "metadata": {},
   "source": [
    "### Why we keep the same pipeline across models\n",
    "\n",
    "In practice, once a problem is identified as a regression task,\n",
    "it is common to try multiple models\n",
    "and compare their performance on the same data.\n",
    "\n",
    "For this reason:\n",
    "- the dataset remains identical\n",
    "- the train-test split remains identical\n",
    "- the preprocessing pipeline remains identical\n",
    "\n",
    "Keeping the same pipeline allows us to:\n",
    "- compare models fairly\n",
    "- attribute performance differences to the model itself\n",
    "- switch models without changing data preparation steps\n",
    "\n",
    "Even if a model does not strictly require scaling,\n",
    "including it in the pipeline ensures consistency\n",
    "and simplifies model comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee57b32",
   "metadata": {},
   "source": [
    "### Why we still apply scaling\n",
    "\n",
    "We apply feature scaling to:\n",
    "- keep the preprocessing pipeline identical\n",
    "- simplify switching between models\n",
    "- avoid conditional logic in the code\n",
    "\n",
    "This makes the project easier to maintain\n",
    "and easier to extend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5deb6",
   "metadata": {},
   "source": [
    "### Important rule: fit only on training data\n",
    "\n",
    "As with other preprocessing steps:\n",
    "- the scaler is fitted on training data only\n",
    "- the same scaler is applied to test data\n",
    "\n",
    "This prevents data leakage\n",
    "and ensures a fair evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcfd1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (kept for pipeline consistency)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a142813",
   "metadata": {},
   "source": [
    "### What we have after this step\n",
    "\n",
    "- scaled training data\n",
    "- scaled test data\n",
    "- a complete and consistent preprocessing pipeline\n",
    "\n",
    "At this point, the data is ready\n",
    "to be used by the Random Forest model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b753fcb",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 5. What is this model? (Random Forest Regression)\n",
    "\n",
    "Before training the model, it is important to understand\n",
    "what Random Forest Regression is trying to do conceptually.\n",
    "\n",
    "Random Forest Regression is an **ensemble model**,\n",
    "meaning it combines the predictions of many simpler models\n",
    "to produce a final result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ecf502",
   "metadata": {},
   "source": [
    "### The core idea\n",
    "\n",
    "Instead of relying on a single model,\n",
    "Random Forest builds **many decision trees**.\n",
    "\n",
    "Each tree:\n",
    "- is trained on a slightly different subset of the data\n",
    "- looks at a different subset of features\n",
    "- makes its own prediction\n",
    "\n",
    "The final prediction is obtained\n",
    "by averaging the predictions of all trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9f887",
   "metadata": {},
   "source": [
    "### Why using many trees helps\n",
    "\n",
    "Individual decision trees:\n",
    "- are easy to understand\n",
    "- but tend to overfit the data\n",
    "\n",
    "Random Forest reduces this problem by:\n",
    "- training many trees\n",
    "- making them as different as possible\n",
    "- combining their predictions\n",
    "\n",
    "Errors made by individual trees\n",
    "tend to cancel out when averaged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4cc807",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Random Forest Regression does not try to find a single rule.\n",
    "\n",
    "Instead, it asks:\n",
    "\"What would many different decision trees predict?\"\n",
    "\n",
    "By combining these answers,\n",
    "it produces robust and flexible predictions\n",
    "on complex regression problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880c2c9",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 6. Model training (Random Forest Regression)\n",
    "\n",
    "In this section we train the Random Forest Regression model.\n",
    "\n",
    "Unlike KNN, Random Forest performs real training:\n",
    "it builds multiple decision trees and learns patterns from the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0838351b",
   "metadata": {},
   "source": [
    "### Important hyperparameters (introduced, not tuned)\n",
    "\n",
    "At this stage we focus on understanding the model,\n",
    "not on optimizing it.\n",
    "\n",
    "We start with a simple configuration and default values.\n",
    "Hyperparameter tuning can be explored later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c4658b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=criterion,-%7B%22squared_error%22%2C%20%22absolute_error%22%2C%20%22friedman_mse%22%2C%20%22poisson%22%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%22squared_error%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"},             default=\"squared_error\"<br><br>The function to measure the quality of a split. Supported criteria<br>are \"squared_error\" for the mean squared error, which is equal to<br>variance reduction as feature selection criterion and minimizes the L2<br>loss using the mean of each terminal node, \"friedman_mse\", which uses<br>mean squared error with Friedman's improvement score for potential<br>splits, \"absolute_error\" for the mean absolute error, which minimizes<br>the L1 loss using the median of each terminal node, and \"poisson\" which<br>uses reduction in Poisson deviance to find splits.<br>Training using \"absolute_error\" is significantly slower<br>than when using \"squared_error\".<br><br>.. versionadded:: 0.18<br>   Mean Absolute Error (MAE) criterion.<br><br>.. versionadded:: 1.0<br>   Poisson criterion.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D1.0\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=1.0<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None or 1.0, then `max_features=n_features`.<br><br>.. note::<br>    The default of 1.0 is equivalent to bagged trees and more<br>    randomness can be achieved by setting smaller values, e.g. 0.3.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to 1.0.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.r2_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestRegressor.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonically increasing<br>  - 0: no constraint<br>  - -1: monotonically decreasing<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multioutput regressions (i.e. when `n_outputs_ > 1`),<br>  - regressions trained on data with missing values.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35f5ec",
   "metadata": {},
   "source": [
    "### What these parameters mean\n",
    "\n",
    "- `n_estimators=100`  \n",
    "  Number of decision trees in the forest.  \n",
    "  More trees usually improve stability, but increase computation.\n",
    "\n",
    "- `random_state=42`  \n",
    "  Ensures reproducibility of results.\n",
    "\n",
    "- `n_jobs=-1`  \n",
    "  Uses all available CPU cores to speed up training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330446d4",
   "metadata": {},
   "source": [
    "### What we have after training\n",
    "\n",
    "After this step:\n",
    "- multiple decision trees have been trained\n",
    "- each tree has learned different patterns\n",
    "- the forest is ready to make predictions\n",
    "\n",
    "Unlike KNN:\n",
    "- training is computationally heavier\n",
    "- prediction is relatively fast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccac03a",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 7. Model behavior and key hyperparameters (Random Forest Regression)\n",
    "\n",
    "In this section we describe how Random Forest behaves\n",
    "and which hyperparameters most strongly influence its predictions.\n",
    "\n",
    "Random Forest does not produce simple, interpretable parameters,\n",
    "but its behavior can still be understood at a high level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18924d76",
   "metadata": {},
   "source": [
    "### Number of trees (`n_estimators`)\n",
    "\n",
    "The number of trees controls:\n",
    "- model stability\n",
    "- variance reduction\n",
    "\n",
    "General behavior:\n",
    "- few trees → higher variance, less stable predictions\n",
    "- many trees → more stable, smoother predictions\n",
    "\n",
    "Beyond a certain point,\n",
    "adding more trees provides diminishing returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab3531",
   "metadata": {},
   "source": [
    "### Tree depth and complexity\n",
    "\n",
    "Each tree in the forest can grow deep and complex.\n",
    "\n",
    "Key parameters that control tree complexity include:\n",
    "- maximum tree depth\n",
    "- minimum number of samples per split\n",
    "- minimum number of samples per leaf\n",
    "\n",
    "More complex trees:\n",
    "- capture fine details\n",
    "- risk overfitting\n",
    "\n",
    "Simpler trees:\n",
    "- generalize better\n",
    "- may underfit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be73a49",
   "metadata": {},
   "source": [
    "### Key takeaway\n",
    "\n",
    "Random Forest behavior is controlled by:\n",
    "- how many trees are used\n",
    "- how complex each tree is\n",
    "- how much randomness is introduced\n",
    "\n",
    "Understanding these elements helps explain\n",
    "why Random Forest often performs well\n",
    "without extensive tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e5afe",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 8. Predictions (Random Forest Regression)\n",
    "\n",
    "In this section we use the trained Random Forest model\n",
    "to generate predictions on unseen data.\n",
    "\n",
    "This step shows how the model behaves in practice\n",
    "after the training phase is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "215b599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test set\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31aa1a0",
   "metadata": {},
   "source": [
    "### What we obtained\n",
    "\n",
    "- `y_pred_rf` contains the predicted target values\n",
    "- predictions are generally smooth and stable\n",
    "- extreme values are handled more robustly than with simpler models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a0b57",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 9. Model evaluation (Random Forest Regression)\n",
    "\n",
    "In this section we evaluate the performance of the Random Forest Regression model\n",
    "by comparing its predictions with the true target values.\n",
    "\n",
    "Using the same evaluation metrics across models\n",
    "allows direct and fair comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e312267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3274252027374033,\n",
       " 0.255169737347244,\n",
       " np.float64(0.5051432839771741),\n",
       " 0.8052747336256919)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute evaluation metrics for Random Forest Regression\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "mae, mse, rmse, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a42a3",
   "metadata": {},
   "source": [
    "### Metrics interpretation\n",
    "\n",
    "- **MAE (Mean Absolute Error)**  \n",
    "  Average absolute difference between predictions and true values.\n",
    "\n",
    "- **MSE (Mean Squared Error)**  \n",
    "  Penalizes large errors more heavily.\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)**  \n",
    "  Expresses prediction error in the same units as the target variable\n",
    "  and is often the most informative metric for model comparison.\n",
    "\n",
    "- **R² score**  \n",
    "  Indicates how much variance in the target variable\n",
    "  is explained by the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39dbc8f",
   "metadata": {},
   "source": [
    "### What to expect from Random Forest results\n",
    "\n",
    "With Random Forest Regression, you will often observe:\n",
    "- lower RMSE compared to simpler models\n",
    "- better handling of non-linear patterns\n",
    "- improved robustness to noise and outliers\n",
    "\n",
    "However:\n",
    "- improvements come at the cost of interpretability\n",
    "- training time and memory usage are higher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c916e7",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 10. When to use it and when not to (Random Forest Regression)\n",
    "\n",
    "Random Forest Regression is often a strong default choice,\n",
    "but it is not always the best solution.\n",
    "\n",
    "Understanding when to use it\n",
    "helps avoid unnecessary complexity and inefficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0adbd2f",
   "metadata": {},
   "source": [
    "### When Random Forest Regression is a good choice\n",
    "\n",
    "Random Forest Regression works well when:\n",
    "\n",
    "- The relationship between features and target is non-linear\n",
    "- The data contains complex interactions between features\n",
    "- The dataset is of small to medium size\n",
    "- Robust performance is more important than interpretability\n",
    "- You want strong results without extensive feature engineering\n",
    "\n",
    "In many real-world problems,\n",
    "Random Forest provides a strong balance\n",
    "between accuracy and reliability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd294656",
   "metadata": {},
   "source": [
    "### When Random Forest Regression is NOT a good choice\n",
    "\n",
    "Random Forest Regression may not be ideal when:\n",
    "\n",
    "- Interpretability is a strict requirement\n",
    "- The dataset is extremely large\n",
    "- Memory usage is a concern\n",
    "- Very fast prediction time is required\n",
    "- A simple linear relationship already explains the data well\n",
    "\n",
    "In these cases,\n",
    "simpler or more specialized models may be preferable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c7794",
   "metadata": {},
   "source": [
    "### Typical warning signs\n",
    "\n",
    "You should be cautious if:\n",
    "\n",
    "- Training time becomes very long\n",
    "- The model uses excessive memory\n",
    "- Performance gains over simpler models are marginal\n",
    "- Model behavior is difficult to explain to stakeholders\n",
    "\n",
    "These signals suggest that Random Forest\n",
    "may not be the most efficient choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6963b2f",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 11. Model persistence (Random Forest Regression)\n",
    "\n",
    "In this section we save the trained Random Forest model\n",
    "and the preprocessing steps used during training.\n",
    "\n",
    "Saving the model allows us to reuse it\n",
    "without retraining and ensures reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c07be",
   "metadata": {},
   "source": [
    "### Why saving the model is important\n",
    "\n",
    "Training a Random Forest can be computationally expensive,\n",
    "especially when many trees are used.\n",
    "\n",
    "Once the model has been trained and evaluated,\n",
    "it is common practice to save it and reuse it later:\n",
    "- in another notebook\n",
    "- in an application\n",
    "- in a production environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4dffd4",
   "metadata": {},
   "source": [
    "### Important rule: save the scaler together with the model\n",
    "\n",
    "Even though Random Forest does not require feature scaling,\n",
    "we still save the scaler.\n",
    "\n",
    "This ensures that:\n",
    "- the same preprocessing pipeline is applied\n",
    "- models can be swapped without changing the input pipeline\n",
    "- results remain consistent across experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1edd0c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\supervised_learning\\\\regression\\\\random_forest_regression\\\\scaler.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model directory\n",
    "model_dir = Path(\"models/supervised_learning/regression/random_forest_regression\")\n",
    "\n",
    "# Create directory if it does not exist\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(rf_model, model_dir / \"random_forest_regression_model.joblib\")\n",
    "joblib.dump(scaler, model_dir / \"scaler.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b753d9c",
   "metadata": {},
   "source": [
    "### Loading the model later (conceptual example)\n",
    "\n",
    "To reuse the model:\n",
    "- load the scaler\n",
    "- scale new input data\n",
    "- load the Random Forest model\n",
    "- generate predictions\n",
    "\n",
    "This guarantees consistency\n",
    "with the original training pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698fad8f",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 12. Mathematical formulation (deep dive)\n",
    "\n",
    "This section provides a deeper explanation of Random Forest Regression\n",
    "from a mathematical and algorithmic perspective.\n",
    "\n",
    "The goal is to understand the principles behind the model,\n",
    "not to derive every formula in detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26224d7c",
   "metadata": {},
   "source": [
    "### From decision trees to Random Forest\n",
    "\n",
    "Random Forest Regression is built on top of **decision trees**.\n",
    "\n",
    "A single decision tree:\n",
    "- recursively splits the feature space\n",
    "- creates regions where predictions are constant\n",
    "- predicts the average target value in each region\n",
    "\n",
    "While individual trees are simple,\n",
    "they tend to overfit the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d060e8",
   "metadata": {},
   "source": [
    "### Introducing randomness\n",
    "\n",
    "Random Forest reduces overfitting\n",
    "by introducing randomness in two main ways:\n",
    "\n",
    "1. **Bootstrap sampling**  \n",
    "   Each tree is trained on a random subset of the training data\n",
    "   sampled with replacement.\n",
    "\n",
    "2. **Feature subsampling**  \n",
    "   At each split, only a random subset of features\n",
    "   is considered.\n",
    "\n",
    "These two sources of randomness\n",
    "make individual trees less correlated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b15df",
   "metadata": {},
   "source": [
    "### Ensemble prediction\n",
    "\n",
    "Let each tree produce a prediction ŷᵢ(x)\n",
    "for an input x.\n",
    "\n",
    "The Random Forest prediction is computed as:\n",
    "\n",
    "- the average of all tree predictions\n",
    "\n",
    "This averaging process:\n",
    "- reduces variance\n",
    "- stabilizes predictions\n",
    "- improves generalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2f852",
   "metadata": {},
   "source": [
    "### Bias–variance perspective\n",
    "\n",
    "Random Forest primarily addresses **variance**.\n",
    "\n",
    "- Individual trees have low bias but high variance\n",
    "- Averaging many trees keeps bias low\n",
    "- Variance is reduced through aggregation\n",
    "\n",
    "This explains why Random Forest often performs well\n",
    "without heavy tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507616c6",
   "metadata": {},
   "source": [
    "### Why scaling does not affect the math\n",
    "\n",
    "Decision trees split data based on feature thresholds.\n",
    "\n",
    "Because these splits depend on order, not magnitude:\n",
    "- feature scaling does not change split decisions\n",
    "- the mathematical behavior of the model remains unchanged\n",
    "\n",
    "This explains why Random Forest does not require scaling,\n",
    "even though we include it for pipeline consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c8f90",
   "metadata": {},
   "source": [
    "### Final takeaway\n",
    "\n",
    "Random Forest Regression replaces a single complex model\n",
    "with an ensemble of simple ones.\n",
    "\n",
    "By combining:\n",
    "- randomness\n",
    "- averaging\n",
    "- independent decision trees\n",
    "\n",
    "it achieves strong performance on complex, non-linear problems,\n",
    "while remaining conceptually grounded and robust.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
