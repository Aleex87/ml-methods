{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f595ac",
   "metadata": {},
   "source": [
    "# Supervised Learning → KNN (Classification)\n",
    "\n",
    "This notebook is part of the **ML-Methods** project.\n",
    "\n",
    "As with the other classification notebooks,\n",
    "the first sections focus on data preparation\n",
    "and are intentionally repeated.\n",
    "\n",
    "This ensures consistency across models\n",
    "and allows fair comparison of results.\n",
    "\n",
    "1. Project setup and common pipeline\n",
    "2. Dataset loading\n",
    "3. Train-test split\n",
    "4. Feature scaling (why we do it)\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "5. What is this model? (Intuition)\n",
    "6. Model training\n",
    "7. Model behavior and key parameters\n",
    "8. Predictions\n",
    "9. Model evaluation\n",
    "10. When to use it and when not to\n",
    "11. Model persistence\n",
    "12. Mathematical formulation (deep dive)\n",
    "13. Final summary – Code only\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## How this notebook should be read\n",
    "\n",
    "This notebook is designed to be read **top to bottom**.\n",
    "\n",
    "Before every code cell, you will find a short explanation describing:\n",
    "- what we are about to do\n",
    "- why this step is necessary\n",
    "- how it fits into the overall process\n",
    "\n",
    "The goal is not just to run the code,\n",
    "but to understand what is happening at each step\n",
    "and be able to adapt it to your own data.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What is KNN Classification?\n",
    "\n",
    "KNN Classification is a **distance-based classification model**.\n",
    "\n",
    "Instead of learning a decision boundary during training,\n",
    "the model makes predictions by comparing data points directly.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## Why we start with intuition\n",
    "\n",
    "KNN is one of the simplest classification models conceptually.\n",
    "\n",
    "All it does is:\n",
    "- measure distances between data points\n",
    "- find the K closest neighbors\n",
    "- assign the most common class among them\n",
    "\n",
    "If this idea is clear,\n",
    "the rest of the notebook becomes easy to follow.\n",
    "\n",
    "-----------------------------------------------------\n",
    "\n",
    "## What you should expect from the results\n",
    "\n",
    "With KNN Classification, you should expect:\n",
    "- locally adaptive decision boundaries\n",
    "- sensitivity to feature scaling\n",
    "- good performance when similar samples exist nearby\n",
    "\n",
    "However:\n",
    "- performance can degrade on large datasets\n",
    "- prediction time increases with dataset size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81049373",
   "metadata": {},
   "source": [
    "___________________________________\n",
    "\n",
    "## 1. Project setup and common pipeline \n",
    "\n",
    "In this section we set up the common pipeline\n",
    "used across classification models in this project.\n",
    "\n",
    "KNN relies heavily on distances,\n",
    "so feature scaling is especially important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8089ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports used across all classification models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd92d0",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 2. Dataset loading\n",
    "\n",
    "In this section we load the dataset\n",
    "used for the KNN classification task.\n",
    "\n",
    "We use the same dataset as in Logistic Regression\n",
    "to allow a direct comparison between models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704d57b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9492577d",
   "metadata": {},
   "source": [
    "### Inputs and target\n",
    "\n",
    "- `X` contains the input features\n",
    "- `y` contains the target labels\n",
    "\n",
    "This is a binary classification problem,\n",
    "where the goal is to assign each sample\n",
    "to one of two possible classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171792b1",
   "metadata": {},
   "source": [
    "### Why using the same dataset matters\n",
    "\n",
    "Using the same dataset across classification models\n",
    "allows us to:\n",
    "- compare performance fairly\n",
    "- isolate model-specific behavior\n",
    "- better understand trade-offs between models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e526e56d",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 3. Train-test split\n",
    "\n",
    "In this section we split the dataset\n",
    "into training and test sets.\n",
    "\n",
    "This step allows us to evaluate\n",
    "how well the KNN classifier generalizes\n",
    "to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d95dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b4c08",
   "metadata": {},
   "source": [
    "### Why this step is important\n",
    "\n",
    "KNN does not learn a model during training.\n",
    "Instead, it relies directly on the training data\n",
    "to make predictions.\n",
    "\n",
    "For this reason:\n",
    "- the training set defines the model’s knowledge\n",
    "- the test set must remain completely unseen\n",
    "\n",
    "This separation is essential\n",
    "to obtain a fair evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c982e1d",
   "metadata": {},
   "source": [
    "### Note on split proportions\n",
    "\n",
    "The choice of train-test split\n",
    "depends on the dataset and problem.\n",
    "\n",
    "Common splits include:\n",
    "- 80 / 20\n",
    "- 70 / 30\n",
    "- 90 / 10\n",
    "\n",
    "Here we use 80 / 20\n",
    "as a reasonable default for demonstration purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214bac96",
   "metadata": {},
   "source": [
    "# ____________________________________\n",
    "## 4. Feature scaling (why we do it)\n",
    "\n",
    "In this section we apply feature scaling\n",
    "to the input features.\n",
    "\n",
    "For KNN Classification, feature scaling is **mandatory**.\n",
    "Without scaling, the model will produce incorrect results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d842a4",
   "metadata": {},
   "source": [
    "### Why scaling is critical for KNN\n",
    "\n",
    "KNN is a **distance-based model**.\n",
    "\n",
    "This means that:\n",
    "- predictions depend entirely on distances between samples\n",
    "- features with larger numerical ranges dominate the distance\n",
    "- unscaled data leads to biased neighbor selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1772022b",
   "metadata": {},
   "source": [
    "### Important rule: fit only on training data\n",
    "\n",
    "As with all preprocessing steps:\n",
    "- the scaler is fitted only on the training data\n",
    "- the same scaler is applied to test data\n",
    "\n",
    "This prevents data leakage\n",
    "and ensures fair evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df6cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (mandatory for KNN)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6aca35",
   "metadata": {},
   "source": [
    "### What we have after this step\n",
    "\n",
    "- scaled training data\n",
    "- scaled test data\n",
    "- a valid input space for distance computation\n",
    "\n",
    "At this point, the data is ready\n",
    "to be used by the KNN classifier.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
